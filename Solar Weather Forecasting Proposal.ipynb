{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Solar Weather Forecasting using Linear Algebra\n",
    "## Summary of proposal\n",
    "\n",
    "\n",
    "### What excites me about this project? Why did I choose it?\n",
    "Just reading the title of the project was enough for me. **This** is what I want to do in life.\n",
    "This is what got me into computer science and macnine learning in the first place. To be able to work on problems in various fields of science and understand them in a way which wasn't even possible a few decades ago.\n",
    "I dream of applying AI and data driven solutions to understand our cosmos even further.\n",
    "I am a few months short of having a full year's worth of professional experience in ML, am well acquainted with SunPy and believe that I would be able to finish this project successfully and on time.\n",
    "\n",
    "### Challenges with the project\n",
    "\n",
    "#### Data Preprocessing\n",
    "\n",
    "The biggest challenge would be the data preprocessing and making it ready to be fed into the learning pipeline.\n",
    "For any Machine Learning project, the preprocessing plays a major role in the ability of the learning algorithm to learn from the dataset.\n",
    "In the Sunspotter dataset, there is a significant bias. The following is a list of the percentage of positive sample per class (not mutually exclusive):\n",
    "\n",
    "| Forcasting Parameter | Percentage of Positive samples |\n",
    "| ---                                | ---                                                |\n",
    "|No-flare                |24.00%                                  |\n",
    "|C1flr12hr               |11.37%                                  |\n",
    "|C1flr24hr               |14.40%                                        |\n",
    "|C5flr12hr               | 8.12%                                  |\n",
    "|C5flr24hr               | 8.97%                                  |\n",
    "|M1flr12hr               | 7.22%                                  |\n",
    "|M1flr24hr               | 7.55%                                  |\n",
    "|M5flr12hr               | 7.56%                                  |\n",
    "|M5flr24hr               | 7.66%                                  |\n",
    "\n",
    "* For dealing with this problem, I propose using a method similar to the one described in the paper `Predicting Solar Flares Using a Novel Deep Convolutional Neural Network` [Xuebao Li, Yanfang Zheng, et al 2020](https://iopscience.iop.org/article/10.3847/1538-4357/ab6d04/pdf).\n",
    "* For the sake of conciseness, the main ideas are:               \n",
    "    * It is pretty obvious that the number of M-level magnetogram samples is far less than that of No-flare/C-level magnetogram samples, which is consistent with the fact most ARs do not yield major flares in the period of any given 24 hr. This would result in a serious class-imbalance issue, which is a major problem in the field of machine learning.\n",
    "    * To deal with this, first ARs are categorized into three levels (i.e., No-flare, C, M). “Level = M” indicates that an AR yields at least one M-level flare; “Level = C” indicates that an AR yields at least one C-level flare but no M-level flares “Level = No-flare” indicates that an AR only yields microflares (weaker than C1.0 flares).\n",
    "    * We shall construct about 10 separate CV data sets by the method of shuffle and split CV based on AR segregation. First, we randomly shuffle the AR numbers in different levels of No-flare/C/M and then split the AR numbers at a ratio of around 80%:20% which would correspond to training and testing data respectively.\n",
    "    * We employ undersampling and image augmentation schemes to alleviate the issue of class imbalance. On the one hand, we undersample the data set by randomly choosing No-flare/C-level samples with around 2 samples per 10 samples. One the other hand, we adopt image augmentation schemes to artificially increase the number of M-level samples by rotating and reflecting images, which makes the model invariant to the rotation and reflection in pixel values.\n",
    "    * The advantage of this method is that in each of the 10 data sets, not only do the samples in the testing data set not overlap with those in the training data set but also the ARs in the testing data set are disjoint from those in the training data set. We train and evaluate our model on these 10 separate training and testing data sets. We adopt the loss function calculated from the weighted cross-entropy loss.\n",
    "\n",
    "* I’ll be modifying the code from the [repository mentioned in the original paper](https://github.com/FlarePrediction/Repository) to produce the 10 CV splits.\n",
    "\n",
    "#### Training Time and Resources\n",
    "Different algorithms will consume a different amount of resources in terms of memory and training time.\n",
    "I shall be running all the algorithms locally on my machine equipped with an NVIDIA 1050Ti GPU.\n",
    "If need be, I’ll migrate to Google Colab.\n",
    "\n",
    "## Implementation\n",
    "I plan on implementing various algorithms in order of increasing model complexity.\n",
    "These models will map various inputs to the following forecast parameters.\n",
    "\n",
    "\n",
    "| Forecast Parameter     | Description                                                                                         |\n",
    "| ---                       | ---                                                                                                |\n",
    "| `c1flr12hr`                 | at least one C1.0 or greater flare within 12 hr after the observation. |\n",
    "| `c1flr24hr`         | at least one C1.0 or greater flare within 24 hr after the observation. |\n",
    "| `c5flr12hr`         | at least one C5.0 or greater flare within 12 hr after the observation. |\n",
    "| `c5flr24hr`         | at least one C5.0 or greater flare within 24 hr after the observation. |\n",
    "| `m1flr12hr`         | at least one M1.0 or greater flare within 12 hr after the observation. |\n",
    "| `m1flr24hr`         | at least one M1.0 or greater flare within 24 hr after the observation. |\n",
    "| `m5flr12hr`         | at least one M5.0 or greater flare within 12 hr after the observation. |\n",
    "| `m5flr24hr`         | at least one M5.0 or greater flare within 24 hr after the observation. |\n",
    "\n",
    "The accuracy of the model in predicting these parameters would be its accuracy in forecasting the solar weather.\n",
    "\n",
    "### Timeline\n",
    "___\n",
    "#### Community Bonding Period (DATE)\n",
    "___\n",
    "\n",
    "- I shall spend this time exploring the dataset, discussing possible modifications to the architectures and hyperparameter tuning with my mentors, and continuing my contributions to SunPy.\n",
    "- I also plan on implementing the SMART algorithm in python from the ground up using the [IDL implementation](https://github.com/TCDSolar/SMART). This will help me understand the various parameters and their generation.\n",
    "\n",
    "___\n",
    "#### Coding Period Begins\n",
    "___\n",
    "\n",
    "#### Week 1 (DATE)\n",
    "- As per the official timeline mentioned, this week will be spent visualising different types of data, the magnetograms, univariate, multivariate analysis of the SMART detection properties with respect to both flare generation and the ELO complexity score. I shall be making all the plots in multiple notebooks for the SunPy examples gallery.\n",
    "\n",
    "#### Week 2 - Week 3 (DATE)\n",
    "\n",
    "- Having already tinkered with the dataset, I have created a few basic plotting functions. Here is the link to the notebook that holds them. Here a few random examples. The red squares have been plotted using the Sunspotter data and the blue rectangles have been plotted from the queried HEK data. All functions are in the above-mentioned link. The red squares have been overplotted on purpose as the Sunspotter dataset lacks the information about the shape of the bounding boxes.\n",
    "\n",
    "![Rectangled AR example 1](https://i.imgur.com/C36St72.png)\n",
    "![Rectangled AR example 2](https://i.imgur.com/HglNyXX.png)\n",
    "\n",
    "- I have also created a few helper functions to query the HEK database using HEKClient. I plan to further work on them and create the SunPy Search Events Object. I wish to give this at least four to five days to make this completely merge ready.\n",
    "\n",
    "#### Week 4 - Week 5 (DATE)\n",
    "\n",
    "- Having completed all the previous tasks, we are now ready to tackle the problem head-on. First, the fourth week shall be used in completing the data preprocessing as described in the previous section.\n",
    "- After ensuring that all the Cross-Validation sets are relatively balanced, the fifth week shall be used to implement a simple logistic regression model which a linear algebra model to map the complexity scores to the flare observations.\n",
    "- This model shall serve as a benchmark for comparing all other models.\n",
    "___\n",
    "#### Phase 1 Evaluation (DATE)\n",
    "___\n",
    "\n",
    "#### Week 6 - Week 7 (DATE)\n",
    "\n",
    "- Here, having completed the data preprocessing earlier, we will be able to use various machine learning algorithms with relative ease. All the following will be implemented using Scikit-Learn library.\n",
    "- For weeks 6 and 7, I shall make various models based on the following algorithms:\n",
    "    \n",
    "    * Decision Trees\n",
    "    * Random Forest\n",
    "    * SVM\n",
    "    * SVM with Kernel\n",
    "\n",
    "- All the implementations will be accompanied by an analysis blog post on the nature of the algorithm, an analysis of the results and possible deductions on the accuracy metric.\n",
    "\n",
    "#### Week 8 (DATE)\n",
    "* Week 8 shall be used to implement models based on:\n",
    "    * XGBoost\n",
    "- Like with the previous implementations, this will be accompanied by an analysis blog post on the nature of the algorithm, an analysis of the results and possible deductions on the accuracy metric.\n",
    "\n",
    "#### Week 9 (DATE)\n",
    "\n",
    "- At this point, we move into the domain of Deep Learning.\n",
    "- For week 9, I shall be implementing a Deep Convolution Neural Network based on the paper, <br/>\n",
    " `Deep Learning-Based Solar Flare Forecasting Model. I. Results for Line-of-sight Magnetograms` [Huang et al.](https://iopscience.iop.org/article/10.3847/1538-4357/aaae00/pdf)\n",
    "\n",
    "This shall be implemented using either the PyTorch or TensorFlow2.0 libraries, which shall be decided after discussing with the mentors.\n",
    "___\n",
    "#### Phase 2 Evaluation (DATE)\n",
    "___\n",
    "\n",
    "#### Week 10 - Week 11 (DATE)\n",
    "- Here I plan on implementing an original idea for a multichannel neural network, which would have the ability to take both the Sunspotter SMART detection values along with the corresponding images. I plan on making these different types of inputs compatible by first training an AutoEncoder network on the Active Region images to learn an effective lower-dimensional encoding for the images. This shall be concatenated and re-normalised with the processed SMART detection values and the complexity score to make the final feed-forward neural network that will learn the mapping.\n",
    "This shall be a rather unchartered territory and I will give a full two weeks to implement this.\n",
    "\n",
    "#### Week 12 - Week 13 (DATE)\n",
    "- The last two weeks of the project shall be used to summarise the results of all the various experiments based on the different algorithms.\n",
    "- After selecting the best performing model, it shall be tested on SDO/HMI data from HEK.\n",
    "- An extensive notebook shall be written detailing the use of the model and possible ways to tweak the hyperparameters.\n",
    "- If time permits, as a side quest, I shall implement a neural network that directly maps the Active Region images with the ELO complexity rating. This shall help in automating the complexity prediction for magnetograms in the future.  \n",
    "\n",
    "___\n",
    "#### Final Evaluation (DATE)\n",
    "___\n",
    "\n",
    "## Personal Info\n",
    "\n",
    "- Time zone: UTC+05:30\n",
    "- GitHub handle: [Raahul-Singh](https://github.com/Raahul-Singh)\n",
    "- Email: raahulsingh002@gmail.com\n",
    "- Riot: @raahulsingh:matrix.org\n",
    "- Phone: +91-8279969625\n",
    "- LinkedIn: [Raahul Singh](https://www.linkedin.com/in/raahulsingh299792458/)\n",
    "\n",
    "### Education\n",
    "\n",
    "- University: Indian Institute of Information Technology, Sri City\n",
    "- Major: Computer Science\n",
    "- Current Year: 2nd year\n",
    "\n",
    "### Open Source background and Programming experience\n",
    "\n",
    "- Programming Languages: Python, C++, C, Java(Basic knowledge)\n",
    "- Contributions to SunPy:\n",
    "  - As of writing this proposal I have 8 merged and 5 WIP PRs on SunPy repo. [Link](https://github.com/sunpy/sunpy/pulls?q=is%3Apr+Raahul+Singh+is%3Aclosed)\n",
    "      <br/>Including one that significantly reduces the download time for the dataset used in this project through the HelioViewer API. [Link](https://github.com/sunpy/sunpy/pull/3862)\n",
    "- Contributions to other repos:\n",
    "  - Parfive\n",
    "      - [Adds support for passing User Agent headers and Proxies](https://github.com/Cadair/parfive/pull/32)\n",
    "  - And other contributions to EinstienPy and ChiantiPy.\n",
    "      \n",
    "\n",
    "### Work Experience\n",
    "\n",
    "##### 1) Global Remote Mentoring (IBM GRM) Intern\n",
    "###### IBM India\n",
    "###### Duration : January 2020 to present\n",
    "- Worked on multimodal datasets containing stereo RGB and Lidar data for autonomous driving.\n",
    "- Studied various network architectures like Frustum-Point Net, Pyramid Stereo Matching Net, etc.\n",
    "- Studied about camera parameters and the linear algebra behind switching from one perspective to another.\n",
    "\n",
    "##### 2) Data Science Intern\n",
    "###### Masho, an e-commerce startup from Bangalore, India\n",
    "###### Duration : August 2019 to November 2019\n",
    "- Worked on cleaning and analysis of principal sourced data.\n",
    "- Implemented Image to Image Similarity model using Siamese Networks for the Recommendation System, giving a robust recommendation.\n",
    "- Contributed to the core Machine Learning Recommendation Engine.\n",
    "\n",
    "#####  3) Machine Learning Intern\n",
    "###### Indian Institute of Technology, Roorkee, India\n",
    "###### Duration : May 2019 to July 2019\n",
    "- Interned at the Biotech Department, working on Data Understanding and Visualization for Post-Harvest Apple data.\n",
    "- Made a model for understanding the behavior of various parameters like Sugar content, Acidity, Firmness, Ethyl Alcohol concentration.\n",
    "- Made a predictor model for charting the evolution of these parameters over a period of six months from harvest.\n",
    "\n",
    "I think I have enough experience with python development to produce high quality, testable code.\n",
    "Further, I have [Letters of Recommendation](https://drive.google.com/open?id=1HTWUlAvQu8iQwauEmSx3T0-cupyuyjpN) from my previous employers, which demonstrate my commitment to the work assigned to me.\n",
    "\n",
    "## You and GSoC\n",
    "\n",
    "### Have you participated previously in GSoC? When? Under which project?\n",
    "**No**, This is my first time participating in GSoC.\n",
    "\n",
    "### Are you also applying to other projects?\n",
    "**No**, I am fully focused on this project.\n",
    "\n",
    "### Commitments\n",
    "I don't have any other internship or work during this summer and have no plans for any vacations either. <br/>\n",
    "I can work full time on the project and can give ~40-50 hours per week and more if required.\n",
    "\n",
    "### Eligibility\n",
    "Yes, I am eligible to receive payments from Google.\n",
    "\n",
    "\n",
    "\n",
    "### References and useful papers\n",
    "\n",
    "* `Deep Learning-Based Solar Flare Forecasting Model. I. Results for Line-of-sight Magnetograms` [Huang et al.](https://iopscience.iop.org/article/10.3847/1538-4357/aaae00/pdf)\n",
    "\n",
    "* `Solar flare prediction using advanced feature extraction, machine learning and feature selection` [Ahmed OW, Qahwaji RSR, Colak T, Higgins PA, Gallagher PTand Bloomfield DS (2013) Solar physics. 283(1): 157-175](https://bradscholars.brad.ac.uk/handle/10454/7581)\n",
    "\n",
    "* `Predicting Solar Flares Using a Novel Deep Convolutional Neural Network` [Xuebao Li, Yanfang Zheng, et al 2020](https://iopscience.iop.org/article/10.3847/1538-4357/ab6d04/pdf`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
